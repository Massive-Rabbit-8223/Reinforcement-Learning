{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_to_list(state):\n",
    "    return [int(x) for x in str(state)]\n",
    "\n",
    "def convert_list_to_state(state_list):\n",
    "    return sum([s*10**(len(state_list)-1-j) for j, s in enumerate(state_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 3, 2, 1, 2, 3, 1, 3]\n",
      "313212313\n"
     ]
    }
   ],
   "source": [
    "sl = convert_state_to_list(313212313)\n",
    "print(sl)\n",
    "ls = convert_list_to_state(sl)\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_win(state, x, o):\n",
    "    state_list = [int(x) for x in str(state)]\n",
    "    \n",
    "    # check columns\n",
    "    for i in range(3):\n",
    "        val = state_list[0+i]*state_list[3+i]*state_list[6+i]\n",
    "        if val == x**3 or val == o**3:\n",
    "            return int(val**(1/3))\n",
    "        \n",
    "    # check rows\n",
    "    for i in range(3):\n",
    "        val = state_list[0+(i*3)]*state_list[1+(i*3)]*state_list[2+(i*3)]\n",
    "        if val == x**3 or val == o**3:\n",
    "            return int(val**(1/3))\n",
    "    \n",
    "    # check diagonals\n",
    "    for i in range(2):\n",
    "        val = state_list[0+(2*i)]*state_list[4]*state_list[8-(2*i)]\n",
    "        if val == x**3 or val == o**3:\n",
    "            return int(val**(1/3))\n",
    "        \n",
    "    return 0    # represents that no one has won yet\n",
    "\n",
    "\n",
    "def game_over(state, x, o):\n",
    "    winner = check_for_win(state, x, o)\n",
    "    if winner:\n",
    "        return winner\n",
    "    elif not \"1\" in str(state):\n",
    "        return 0    # represents a draw\n",
    "    else:\n",
    "        return -1   # represents that the game is not over yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def init_state_values():\n",
    "#    state_value_dict = {}\n",
    "#    for state in tqdm(range(111111111, 333333333 + 1)):\n",
    "#        check = True\n",
    "#        for i in [0,4,5,6,7,8,9]:\n",
    "#            if str(i) in str(state):\n",
    "#                check = False\n",
    "#                break\n",
    "#        if check == True:\n",
    "#            state_value_dict[state] = 0.5\n",
    "#            \n",
    "#    return state_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_states(current_state, player):\n",
    "    state_list = [int(x) for x in str(current_state)]\n",
    "\n",
    "    next_states_list = []\n",
    "    for i in range(len(state_list)):\n",
    "        if state_list[i] == 1:\n",
    "            possible_state_list = state_list[:] # copy list by value (hopefully!)\n",
    "            possible_state_list[i] = player\n",
    "            possible_state = convert_list_to_state(possible_state_list)\n",
    "            next_states_list.append(possible_state)\n",
    "\n",
    "    return next_states_list\n",
    "\n",
    "def select_next_state(state_value_dict, next_state_list, selection_criterion):\n",
    "    value_list = []\n",
    "    for next_state in next_state_list:\n",
    "        if next_state in state_value_dict.keys():\n",
    "            state_value = state_value_dict[next_state]\n",
    "            value_list.append(state_value)\n",
    "        else:\n",
    "            value_list.append(0.5)\n",
    "    next_state = random.choices(population=next_state_list, weights=value_list, k=1)[0]\n",
    "    if not next_state in state_value_dict.keys():\n",
    "        state_value_dict[next_state] = 0.5\n",
    "\n",
    "    return next_state, state_value_dict\n",
    "\n",
    "def take_action(state_value_dict, current_state, player, selection_criterion):\n",
    "    next_state_list = get_next_states(current_state, player)\n",
    "    next_state, state_value_dict = select_next_state(state_value_dict, next_state_list, selection_criterion)\n",
    "\n",
    "    return next_state, state_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[223112111, 213212111, 213122111, 213112211, 213112121, 213112112]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_states(current_state=213112111, player=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_value_dict = {} #init_state_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_value_dict.keys()) == 3**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_over(233233222, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.74878501e-43, 7.47197234e-43])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax([100,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTTAgent():\n",
    "    def __init__(self, step_size, default_value, exploration_discounting, player_description, strategy) -> None:\n",
    "        self.state_value_dict = {}\n",
    "        self.step_size = step_size\n",
    "        self.default_value = default_value\n",
    "        self.exp_disc = exploration_discounting\n",
    "        self.strategy = strategy\n",
    "        if player_description == \"X\":\n",
    "            self.player_description = 2\n",
    "        elif player_description == \"O\":\n",
    "            self.player_description = 3\n",
    "        else:\n",
    "            print(\"ERROR, invalid, player description\")     # replace with actual error\n",
    "\n",
    "        self.experience = 1     # gets updated by one after every game played, or won?\n",
    "        self.action_list = []\n",
    "\n",
    "    def convert_list_to_state(self, state_list):\n",
    "        return sum([s*10**(len(state_list)-1-j) for j, s in enumerate(state_list)])\n",
    "\n",
    "    def _get_next_states(self, current_state):\n",
    "        state_list = [int(x) for x in str(current_state)]\n",
    "\n",
    "        next_states_list = []\n",
    "        for i in range(len(state_list)):\n",
    "            if state_list[i] == 1:\n",
    "                possible_state_list = state_list[:] # copy list by value (hopefully!)\n",
    "                possible_state_list[i] = self.player_description\n",
    "                possible_state = self.convert_list_to_state(possible_state_list)\n",
    "                next_states_list.append(possible_state)\n",
    "\n",
    "        return next_states_list\n",
    "\n",
    "    def _select_next_state(self, next_state_list):\n",
    "        value_list = []\n",
    "        optimal_action = False\n",
    "\n",
    "        for next_state in next_state_list:\n",
    "            if next_state in self.state_value_dict.keys():\n",
    "                state_value = self.state_value_dict[next_state]\n",
    "                value_list.append(state_value)\n",
    "            else:\n",
    "                value_list.append(self.default_value)\n",
    "\n",
    "        if self.strategy == \"exploratory\":\n",
    "            next_state = random.choices(\n",
    "                population=next_state_list, \n",
    "                weights=softmax([value*(10-math.log(self.exp_disc**math.sqrt(self.experience))) for value in value_list]), \n",
    "                k=1\n",
    "            )[0]        # that's the policy\n",
    "        else:\n",
    "            next_state = next_state_list[np.argmax(value_list)] \n",
    "            \n",
    "        if not next_state in self.state_value_dict.keys():\n",
    "            self.state_value_dict[next_state] = self.default_value\n",
    "\n",
    "        if self.state_value_dict[next_state] == max(value_list):\n",
    "            optimal_action = True\n",
    "\n",
    "        return next_state, optimal_action\n",
    "\n",
    "    def take_action(self, current_state):\n",
    "        next_state_list = self._get_next_states(current_state)\n",
    "        next_state, optimal_action = self._select_next_state(next_state_list)\n",
    "\n",
    "        self.action_list.append((next_state, optimal_action))\n",
    "\n",
    "        return next_state, optimal_action\n",
    "    \n",
    "    def _update_value(self, state_t, state_t1):\n",
    "        value_t = self.state_value_dict[state_t]\n",
    "        value_t1 = self.state_value_dict[state_t1]\n",
    "\n",
    "        self.state_value_dict[state_t] += self.step_size*(value_t1-value_t)#**math.sqrt(self.experience)))\n",
    "\n",
    "    def update_values(self, reward):\n",
    "\n",
    "        #print(self.action_list)\n",
    "        \n",
    "        last_state = self.action_list[-1][0]\n",
    "        self.state_value_dict[last_state] = reward\n",
    "\n",
    "        for i in range(len(self.action_list)-1, 1, -1):\n",
    "            optimal_move = self.action_list[i][1]\n",
    "\n",
    "            if optimal_move:\n",
    "                state_prev = self.action_list[i-1][0]\n",
    "                state_now = self.action_list[i][0]\n",
    "\n",
    "                self._update_value(state_prev, state_now)\n",
    "\n",
    "        self.experience += 0.1\n",
    "        self.action_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTTEnv():\n",
    "    def __init__(self) -> None:\n",
    "        self.state_list = []\n",
    "        self.player_x = 2\n",
    "        self.player_o = 3\n",
    "        self.winner = None\n",
    "\n",
    "    def move(self, player, action):\n",
    "        self.state_list.append((action, player))\n",
    "\n",
    "        return self.game_over(action, player)\n",
    "\n",
    "    def check_for_win(self, state, player):\n",
    "        state_list = [int(x) for x in str(state)]\n",
    "        \n",
    "        # check columns\n",
    "        for i in range(3):\n",
    "            val = state_list[0+i]*state_list[3+i]*state_list[6+i]\n",
    "            if val == player**3:\n",
    "                return 1\n",
    "            \n",
    "        # check rows\n",
    "        for i in range(3):\n",
    "            val = state_list[0+(i*3)]*state_list[1+(i*3)]*state_list[2+(i*3)]\n",
    "            if val == player**3:\n",
    "                return 1\n",
    "        \n",
    "        # check diagonals\n",
    "        for i in range(2):\n",
    "            val = state_list[0+(2*i)]*state_list[4]*state_list[8-(2*i)]\n",
    "            if val == player**3:\n",
    "                return 1\n",
    "            \n",
    "        return -1    # represents that no one has won yet\n",
    "\n",
    "\n",
    "    def game_over(self, state, player):\n",
    "        reward = self.check_for_win(state, player)\n",
    "        if reward > 0:\n",
    "            self.winner = player\n",
    "            return reward\n",
    "        elif not \"1\" in str(state):\n",
    "            return -1    # represents a draw\n",
    "        else:\n",
    "            return 0   # represents that the game is not over yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_1 = TTTAgent(\n",
    "    step_size=0.9,\n",
    "    default_value=0.5,\n",
    "    exploration_discounting=0.9,\n",
    "    player_description=\"X\",\n",
    "    strategy=\"greedy\"\n",
    ")\n",
    "\n",
    "agent_2 = TTTAgent(\n",
    "    step_size=0.9,\n",
    "    default_value=0.5,\n",
    "    exploration_discounting=0.9,\n",
    "    player_description=\"O\",\n",
    "    strategy=\"exploratory\"\n",
    ")\n",
    "\n",
    "\n",
    "env = TTTEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [04:47<00:00, 3484.00it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "players = [agent_1, agent_2]\n",
    "\n",
    "num_epochs = 1000000\n",
    "win_dict = {\n",
    "    2: 0,\n",
    "    3: 0\n",
    "}\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    current_state = 111111111\n",
    "    game_finished = False\n",
    "    players.reverse()\n",
    "    while not game_finished:\n",
    "        for i in range(len(players)):\n",
    "            next_state, _ = players[i].take_action(current_state)\n",
    "            current_state = next_state\n",
    "            reward = env.game_over(current_state, players[i].player_description)\n",
    "\n",
    "            if reward == 1:\n",
    "                win_dict[env.winner] += 1\n",
    "                players[i].update_values(reward)\n",
    "                players[i-1].update_values(-reward)\n",
    "                game_finished = True\n",
    "                break\n",
    "            elif reward == -1:\n",
    "                players[i].update_values(0)\n",
    "                players[i-1].update_values(0)\n",
    "                game_finished = True\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 312659, 3: 222911}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent_1.state_value_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1058"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent_2.state_value_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build interface, to play against agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
